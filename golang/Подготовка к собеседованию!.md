# Скрининг
https://oil-delphinium-010.notion.site/Backend-programing-710573de8bcd4ed69cfc078b33d3833d?p=157b4893b5c04d17ab945d464ae7e041&pm=s

https://habr.com/ru/articles/786826/

Golang – это компилируемый многопоточный язык программирования, который позволяет создавать целые системы подключенных контроллеров, и эффективно работать с базами данных.
## О себе

Еще до поступления в вуз начал заниматься программированием. Первым языком, который я изучил был Python, но я быстро понял что это мне не подходит. По совету своего друга начал изучать JS и сразу углубился в DataSciens. С этим языком я работал на протяжении года и написал с десяток монолитов на разных фреймворках по типу Node.js, Express и Nest, а так же имел дела с Fullstack разработкой, языком разметки гипертекста (HTML) и языком описания стилей (CSS). Нашел первую работу - был стартап, суть создание сайта по изучению SQL (практика плюс теория) и тимлид писал расширение в VSCode для визуализации таблиц, связей и в целом всех SQL запросов. Проект закончился, так как такое расширение создали за пару месяцев до конца нашей работы и в первый же месяц было около миллиона скачиваний (Китаец опередил). Позже, из-за того что немного подустал, я решил попробовать язык программирования Golang, к тому же на тот момент у меня были друзья которые уже работали на Go и они любезно обьяснили, что строго типизированные языки топ и гошка сейчас один из самых востребованных языков, она стал моей основной областью развития. На работе помогли знания ноды, так как мы пилили монолит с ноды на микросервисы гошку. Потом оптимизировали работу приложения, дописывали микросервисы и поддерживали продукт. Получается 10 числа много разрабов сократили, так как все доработки по сайту сделали, оставалось поддерживать сайт и бессмысленно было оставлять большое количество разработчиков.
 

## Чем занималась компания:

Компания занималась внедрением способов оплаты для клиентов. Когда я только пришел в компанию был монолит на ноде, мы должны были переписать на гошку. После того как переписали, лично я разрабатывал 2 дополнительных микросервиса:
- Шадоулер (планировщик);
- Нотификационный сервис.

## Что входило в мои обязанности 

В мои же обязанности входила разработка высокопроизводительных микросервисов с использованием технологий gRPC и Gin, написание эффективного и оптимизированного кода на языке программирования Golang, участие в проектировании архитектуры приложений и оптимизация. Также мне приходилось проводить код-ревью и участвовать в обсуждении технических решений с коллегами.

## Что я делал в компании:

**Вкратце:**
- Шадоулер это такой планировщик, в нем можно было создать таску на определеный итервал и на определеное время
- Нотификационный сервис который мог через кафку присылать отчеты, это я считаю своим достижением - у меня получилось добиться 5000 сообщений в секунду.

**Подробнее:**
Микросервисы по сути связаны между собой, это 
нотификационный(сервис уведомлений) сервис и шэдулер(планировшик).

Нотификационный с более сложной логикой, так как он подключался к разным мерчантам(принимает оплату) и терминалам(то через что проходит оплата), вытаскивал из ЕС настройки, отправлял по http или email, либо другими транспортам (транспортным протоколам, в основном http) во вне (во внешние зависимости чистой архитектуры)

Шедовлер это некий планировщик, в нем можно было создать таску(задачку) на определенное время с определенными интервалами, к примеру каждые 4 дня отправлять нотификацию об отчетах, он также под кафкой отправлял уведомление в EC и EC уже отправляла уведомление по нужному доступу

- Шадоулер
- Нотификационный сервис

## Команда:

- 2 Гошера
- 1 ТехЛид, по совместительству третий гошер
- 3 Frontend (React.js / Vue3, Tailwind, Scss, TypeScript)
- 1 Designer (Figma)
- 1 Тестировщик
## Стэк компании:

**Стэк:**
- PostgreSQL
- Redis (хранит данные в оперативной памяти)
- Swagger
- Kafka Apache
- Docker
- gRPC
- Golang
- Gin

pig-Простая оболочка [pgx](https://github.com/jackc/pgx) для выполнения и [сканирования](https://github.com/alexeyco/pig) результатов запроса.
pgx — это чистый драйвер Go и набор инструментов для PostgreSQL.
Драйвер pgx — это низкоуровневый высокопроизводительный интерфейс, который предоставляет специфичные для PostgreSQL функции, такие как `LISTEN`/ `NOTIFY`и `COPY`. В комплект также входит адаптер для стандартного `database/sql`интерфейса.

ClickHouse — это самая быстрая и наиболее ресурсоэффективная база данных с открытым исходным кодом для приложений и аналитики реального времени.
Клиент базы данных Golang SQL для [ClickHouse](https://clickhouse.com/) .
## Почему решили уйти с прошлой работы:

Проект заканчивался (мы остались в хороших отношениях).
## Сильные стороны:

Я думаю что моей самой сильной стороной является внимательность. На прошлой месте пребывания мне сказали что у меня отличное отношение к работе и к людям, что умею вдохновлять всех вокруг себя. А еще предыдущие руководители замечали что на меня всегда можно положиться. 
## Слабые стороны:

Люблю поговорить про разные технологии, и про интересные факты.

## Работали не очень официально и зп получал в крипте (эфир) самозанятость
## Что важно на работе:

Для меня на работе важен комфорт и хорошая команда, которой я могу помочь и которая может помочь мне в ответ

## Как планируешь развиваться на проекте:

Для начала познакомлюсь с командой потом посижу пару деньков посмотрю проект, разберусь в архитектуре, изучу технологии с которыми был не знаком в течении двух дней (если такие будут, условный кубер) и приступлю к работе.

## Мои вопросы:…

Можете рассказать про свою команду? 
Расскажите про цели вашей компании на ближайший год?
Расскажите поподробнее про команду, какой примерно возраст у разработчиков? Какой стек на вашем проекте?
## Подробнее про микросервисы

Вопросы:
- Что делает Нотификационный сервис?
	- В Нотификационный сервис приходит уведомление о том что нужно запланировать такую то нотификацию, и он должен уведомить хост, дальше может кинуть уведомления по email или телеграмм.

- Как вы отслеживали ошибку (Менеджер мониторинг падения)?
	- grafana изменяется график

%%grafana - Это программное средство мы используем для визуализации и анализа данных как внутренних, так и внешних проектов%%

- Как замеряли нагрузку?
	- grafana

- Как развертывали?
	- devops настраивали через пайплайн, если он успешен, то там был настроен дэплой
	- открывал несколько vs кодов запускал каждый сервис 

%%Пайплайн (от англ. pipeline — трубопровод) — это последовательность действий или процессов, которые выполняются для достижения заданной цели. Такой метод управления проектом состоит из этапов, на каждом из которых выполняется определенная задача или набор задач. Каждый этап имеет свои входные и выходные данные, условия запуска и завершения, зависимости от других этапов. Пайплайны бывают разными по сложности и длительности, в зависимости от типа и масштаба проекта, используемых технологий и инструментов, требований к качеству и безопасности продукта.%%







# Собес

## Отличия Go от JS:

**Производительность.**. В реальных условиях сетевого взаимодействия и взаимодействия с базой данных Go и Node.js показывают равные результаты.  
  
**Параллелизм.** Здесь Go определенно выигрывает: он использует легкие потоки — goroutines, а Node.js унаследовал механизм цикла обработки событий JavaScript, который имеет свои недостатки.  
  
**Кривая обучения.** Благодаря JavaScript, согласно недавнему опросу Node.js стал одним из самых быстрорастущих языков разработки. Причиной этому является проста освоения, обширная документация и большое открытое комьюнити. Go, также довольно легок в обучении. Опрос PW Engine показал, что большинство разработчиков считают его очень интуитивным, а это большой плюс если компании требуется как можно быстрее ввести новых сотрудников в рабочий процесс. Так что, здесь тоже ничья.  
  
**Обработка ошибок.** Здесь мнения расходятся. Go использует явную проверку ошибок, в отличии от неявного try\catch. за счет этого проверок на ошибки становиться больше, но они понятней, так как находятся ближе к месту их возникновения и направлены на определение проблемы в конкретном месте, во второй версии Go обещают добавить check\handle. Node.js использует принцип try\catch, общий для многих языков, и обладающий определенными ограничениями.  
  
**Фронтенд и бэкенд.** Go нацелен на разработку параллельных сервисов, поэтому он отлично подходит для серверной части. И хотя для Go есть фреймворки для создания веб-приложений, такие как Beego и gopherjs, гораздо удобнее создавать современный пользовательский интерфейс с JavaScript. К тому же исходя из факта, что JS господствует на фронтенде, то проще поддерживать и бэкенд и фронтенд на одном языке — JavaScript  
Выбор разработчиков. Здесь нет сомнений: JavaScript остается наверху так как уже давно влился в рабочие процессы разработчиков во всем мире. Конечно, Go вошел в топ-20 самых популярных технологий, но, к сожалению, он по-прежнему далек от JavaScript с точки зрения популярности.  
  
**Sync/Async IO (синхронный/асинхронный ввод-вывод).** Node.js славится своей неблокирующей моделью ввода-вывода, которая делает его легким и эффективным с точки зрения ресурсов. Но у него также есть недостатки, например, бесконечные обратные вызовы в коде и странные трассировки стека. С другой стороны, Go, используя свой планировщик, рекомендующий разработчикам использовать синхронные операции, опираясь на различные инструменты, предоставляемые ОС, для повышения эффективности и сокращения блокировки ресурсов.  
  
**Работа на устройствах.** С менеджером пакетов NPM Node.js можно эффективно использовать в качестве среды программирования на одноплатниках, таких, как Raspberry Pi, [Iskra Js](http://amperka.ru/product/iskra-js) или [BeagleBone Black](http://beagleboard.org/BLACK). NPM содержит около 80 пакетов с открытым исходным кодом для контроллеров Arduino, [Intel IoT Edison](https://software.intel.com/en-us/iot/hardware/discontinued), Raspberry Pi и более 30 пакетов для различных устройств и датчиков Bluetooth. Что касается Go, то он хорошо подходит плат Raspberry Pi, так как он запускает полную сборку Linux. Однако маломощные IoT-устройства, такие как Arduino, не могут работать с двоичным кодом Go. Вот почему был создан фреймворк Gobot. Он поддерживает множество платформ, Bluetooth LE устройств и даже интерфейс NeuroSky.  
  
**Библиотеки.** По количеству библиотек JavaScript конечно же пока обходит своего оппонента, однако в определенных областях, например, в математике, для Go написаны более мощные инструменты по работе со сложной математикой и анализом данных.

## Плюсы и минусы Go

Плюсы:
- Простой синтаксис
- Легкий для новичков
- Существование гарбиш коллектора
- Много встроенных инструментов для разработчиков
	- пример
		- gas найдет уязвимости
		- go vet обнаружит ошибки в коде
		- gofmt правильно отформатирует код, проставит пробелы для выравнивания и табы для отступа
- Большое количество библиотек
- Высокая производительность
- Надёжность 
	- грамотное использование памяти и вычислительных ресурсов
- Кроссплатформенность
- Поддержка UTF-8
	- Я читал и по моему в Go одна из наиболее полных среди всех ЯП

Минусы:
- Ограниченный функционал
	- Создание графического интерфейса (плохо)
- Размер
	- При компиляции маленькой программы можно получить файл в несколько Мб
- Работа с памятью
	- Не существует средства ручного управления памятью
	- Нельзя настроить поведение сборщика мусора





## Общие данные  

________________________________________________________________________

спринт - это короткий промежуток времени на который обычно расписывают задачи, зачастую неделю-две (говори 2-3 спринта, в зависимости от сложности, на некоторые сервисы закладывали по 5 спринтов, но у меня получалось сделать быстрее)
one to one - созвоны один на один, условно лид и ты
дэйли - созвоны внутри команды ежедневные часиков в 10-11, там каждый по очереди рассказывает что делал вчера и что будет делать сегодня
Дэмо, у нас это ежемесячный созвон, внутри компании (большой дэйли)

__________________________________________________________________________

Парсинг — это сбор информации из сторонних источников и сайтов для использования полученных данных в различных целях, от аналитики до копирования. 

Мапить — обычно означает "произвести отображение контекста А на контекст Б". Результатом отображения является набор соответствий значений. 

Валидация — это проверка систем, процессов, пользователей на то, насколько они соответствует определенным установленным требованиям. 

HTTP-Запросы (Requests) — сообщения, которые отправляются клиентом на сервер, чтобы вызвать выполнение некоторых действий.

 `deadlock` - это ситуация, когда несколько горутин блокируются, ожидая друг друга, и ни одна из них не может продолжить выполнение. Это может произойти, когда горутины блокируются на ресурсах, которые не могут быть освобождены.

`livelock` - это ситуация, когда несколько горутин активно выполняют операции, но эти операции не влияют на продвижение состояния программы вперед. Это может произойти, когда горутины постоянно переключаются между собой, не делая прогресса в выполнении задачи.
DataRace - это обращение к одним и тем же данным из разных горутин, где одно из обращений - запись. 

Сериализация — это **преобразование объекта или дерева объектов в какой-либо формат (обычно текстовый или в набор байт) с тем, чтобы потом исходные объекты можно было восстановить из этого формата**. Используется, например, для сохранения состояния программы (то есть, некоторых её объектов) между запусками.

**Race condition (состояние гонки)** - это ситуация, при которой несколько потоков (или процессов) одновременно пытаются выполнить операции чтения или записи к общим ресурсам без должной синхронизации.

В Golang замыкание — это **функция, которая ссылается на переменные вне своей области видимости**

Захват переменных - 

Инвертирование зависимостей - Её идея заключается в том, что высокоуровневая логика не должна зависеть от низкоуровневых реализаций.

Куча - это древовидная структура данных, которая удовлетворяет следующим свойствам:

* Это полное двоичное дерево, то есть каждый уровень дерева заполнен узлами, за исключением возможно последнего уровня.
* Куча имеет свойство кучи, которое означает, что для каждого узла значение ключа родительского узла больше или равно значению ключа дочернего узла.

**Бинарная куча**

Бинарная куча - это особый тип кучи, в которой каждый узел имеет максимум два дочерних узла. Бинарные кучи обычно реализуются с использованием массива, где каждый элемент массива соответствует узлу в дереве.
## Типы данных Go:

Примитивные типы данных в Go 8(?):
int                byte
uint              rune
float             string 
bool             complex
Составные типы данных 6(?):
masive*        slice*
struct*          map*
pointer*       interface*

Method (метод)
Boolean (логический тип)
Numeric (численный)
String (строковый)
Array (массив)
Slice (срез)
Struct (структура)
Pointer (указатель)
Function (функция)
Interface (интерфейс)
Map (карта)
Channel (канал)

## String (строка)

Строка под капотом - это массив байт или рун, в зависимости от того что находится в строке.
Строки - имутабельны.
**Оператор len для строчки** возвращает количество байт, то есть на него не стоит опираться если у тебя какой нибудь unicode, ну в плане того что ты хочешь символы читать. Там какой то есть метод в пакете strings кажется.
**С оператором квадратные скобки** будет то же самое. 

Руна в Go представляет собой отдельный символ Unicode. Она является типом данных int32 с диапазоном от -0x10FFFF до 0x10FFFF.
Руны используются в Go для:

* Представления символов Unicode в строках.
* Обработки символов из различных языков и алфавитов.
* Сравнения и сортировки строк по символам.
## Switch (Свич)

Когда срабатывает условие какого-либо case, программа выполняет блок и выходит из конструкции switch без необходимости писать break. Если выражение отсутствует - для компилятора выглядит как: switch true. При написании fallthrough, мы можем провалиться в следующий идущий блок.
## Struct (структура) 

Описывают поведение какого либо объекта которое мы ожидаем 
для соответствия некому интерфейсу тип данных или структура должна реализовывать все методы данного интерфейса
объект реализует интерфейс, если он содержит все методы этого интерфейса, независимо от связей, наследования и принадлежности к какой-либо конкретной структуре.

Struct tagging - это способ добавить метаданные к полям struct в Go, используя теги в формате строк. Эти теги могут быть использованы библиотеками для сериализации и десериализации данных, таких как JSON, XML, и другими.

Struct tagging - это мощный инструмент, который позволяет разработчикам контролировать, как данные сериализуются и десериализуются.
## Interface (интерфейс)

В Go интерфейс - это тип, который определяет набор методов, которые должны быть реализованы типом, который его имплементирует. Интерфейс может быть пустым (`interface{}`), что означает, что он может хранить значение любого типа. Интерфейс также может быть не пустым, в котором указываются конкретные методы, которые должны быть реализованы типом, который его имплементирует.

Интерфейс в Go - это абстрактный тип, который не может быть создан напрямую. Вместо этого, мы создаем переменную интерфейсного типа и присваиваем ей значение конкретного типа, который имплементирует интерфейс.

Интерфейсы в Go используются для реализации полиморфизма, позволяя использовать общую сигнатуру методов для различных типов. Каждый тип может реализовать интерфейс по-своему, что позволяет использовать разные типы в контексте одного интерфейса.

Также, интерфейсы в Go используются для реализации DuckTyping, что означает, что тип может быть использован в контексте интерфейса, если он имплементирует все методы, указанные в интерфейсе, даже если он неявно не наследует тип данных.

В целом, интерфейсы в Go - это мощный инструмент для обеспечения гибкости и расширяемости кода, позволяя использовать разные типы в контексте одного интерфейса.

Специальный тип в go представляющий из себя набор методов. Интерфейсы обладают типом и значением, они легко имплементируют методы наследуя тип данных. Используя интерфейсы в go реализовывается полиморфизм - у вас есть общая сигнатура, но каждый тип может быть реализован по своему.

Пустой интерфес подходи под все типы потому что всех типов в golang 0 методов.

Также в Go присутствует duckttyping - это так скажем, если объект реализовывает все методы данного интерфейса, то он автоматически реализует интерфейс.

## Const (константа)

В константы можно помещать только определенные типы данных. Для последовательно идущих числовых констант в качестве индификатора используют iota
- Ключевое слово `iota` представляет последовательные целочисленные константы 0, 1, 2,…
- Оно обнуляется каждый раз, когда `const` появляется в исходном коде
- И увеличивается после каждой спецификации `const`
## Mas (массив)

Массив по сути фиксированный кусок памяти, у которого мы должны указать его длину и вместимость перед компиляцией. Массивы в Go передаются по значению, следовательно, любое изменение внутри функции не влияет на исходный массив.
## Slice (слайс)

Слайс — это массив неопределенной длины (динамический массив) который под капотом слайс хранит также ссылку на базовый массив, при переполнении вместимости, данные копируются в новый массив с вместимостью в 2 раза больше предыдущей, после go 1.18 вместимость увеличивается на определенный коэффициент:| до 256 → x2 | до 512 → x1.63 | до 1024 → x1.44 | до 2048 → x1.35 | до 4096 → x1.30 |
В слайсы можно добавлять элементы с помощью встроенной функции func append(названиеМассива, "чтоДобавить") которая возвращает новый слайс с добавленным элементом.
Встроенная функция make позволяет управлять длиной и вместительностью.
сли в функции происходят изменения элементов, но вам нельзя затрагивать входной слайс. В языке есть встроенная функция func copy(dst, src []Type) int, которая копирует слайс src в слайс dst и возвращает кол-во скопированных элементов.
В Go как и в других языках присутствует сортировка, осуществляется она за счет метода sort.Slice(). Благодаря пустому интерфейсу interface{} мы можем принимать на вход любой тип данных и после сортировать.

Сложность выполнения операций у слайса:
- При обращению к одному элементу сложность будет константной;
- Когда происходит вставка в конец и у нас не переполняется слайс, то сложность тоже будет константной;
- В случае если мы вставляем в начало или в конец с переполнением, будет линейная сложность;
- При удалении из начала - линейная, так как придётся смещать все элементы;
- Удаление из конца константная сложность.
**Вставка и чтение из неинициализированного слайса (ок/не ок)**
OK
**Обращение к неинициализированному слайсу (ок/не ок)**
Не ок, скажет что ты вышел за пределы доступного.
## Map (мапа)

В Go мапа - это хэш таблица.
Если смотреть на уровень выше, то мапа - это просто неотсортированный контейнер данных ключ-значение.
В качестве ключа можно указать почти все типы данных кроме:
- slices
- maps
- funcrions
- struct с incomparable (типами полей)


Она работает путем вычисления **хеш-функции** от ключа, которая возвращает число, представляющее "адрес" в таблице. Этот адрес используется для хранения значения, связанного с ключом.

**Процесс добавления данных в мапу:**

1. Вычисляется хеш-функция от ключа.
2. Хеш-функция возвращает индекс элемента в массиве хеш-таблицы.
3. Если в элементе массива еще нет связного списка, создается новый связный список.
4. Новая пара ключ-значение добавляется в конец связного списка.

Если хеш-код для двух или более ключей одинаковый (**коллизия**), значения хранятся в одном и том же связном списке. Go использует **цепочки** для разрешения коллизий.

Вот пример добавления данных в мапу в Go:

```go
// Создать пустую мапу
myMap := make(map[string]int)

// Добавить пару ключ-значение в мапу
myMap["apple"] = 10
```

**Сложность:**

Добавление данных в мапу в Go имеет временную сложность **O(1)** в среднем. Однако в худшем случае (при большом количестве коллизий) сложность может достигать **O(n)**, где **n** — количество пар ключ-значение в мапе.

**Эффективность:**

Эффективность добавления данных в мапу в Go зависит от следующих факторов:

* **Размер массива хеш-таблицы:** Больший размер массива приводит к меньшему количеству коллизий и лучшей эффективности.
* **Распределение ключей:** Ключи должны быть равномерно распределены по массиву хеш-таблицы, чтобы избежать коллизий.
* **Качество хеш-функции:** Хорошая хеш-функция должна минимизировать коллизии.

Также есть механизм эвакуации данных, он считает среднее значение по бакетам, и если значение больше по моему 6,5, то он делает эвакуацию данных, то есть выделяет новый кусок памяти и перекидывает туда данные. 

Коллизия
Когда коллизия происходит, вот мы прилетаем в бакет и к примеру у нас там уже забился бакет, мы можем начать плодить на конкретный диапазон хэшей связный список бакетов, ну и когда идет операция чтения он залетает в бакет, начинает проверять если никого не нашел дальше смотрит есть ли еще один бакет в связном списке, если есть он там проверяет, если там не нашел, то всё сорян нет такого.

Вставка и чтение из неинициализированной мапы:
- Вставка это конечно печально, будет паника, типичная ошибка.
- Чтение ну вроде нормально.

#sync.Map - предоставляет атомарный доступ
Под атомарным **доступом** будем понимать такое обращение к переменной или периферийному регистру, которое не приведет к конфликту при возникновении прерывания или приоритетного вытеснения задачи в RTOS системах во время выполнения операции.
## Pointer (указатель)

нашем языке есть указатели, мы можем их использовать через символ *int, *string, *bool . Они хранят в себе адрес ячейки памяти значения либо другого указателя. Чтобы получить указатель на переменную используется &переменная Если мы попробуем вывести указатель, то мы получим его адрес, для его разыменования, в вызове используется *переменная. Указатели нужны для работы с типами, переиспользовании их и тд.


## Утиная типизация  

Реализация всех методов используемых для имплементации какой-либо структуры.
## Go'рутины

Горутина - это легковесный поток, по сути сущность которая управляется гошным шедулером(планировщиком). В отличие от потока у горутины динамически расширяемый стэк. 

GOMAXPROCS - отвечает за количество используемых потоков.

Горутина в Go - это легковесный поток, который управляется гошным шедулером. Она имеет динамически расширяемый стэк и может быть создана с помощью ключевого слова `go`. Горутины могут выполняться одновременно с основной программой, но они отличаются от тредов в своей реализации и поведении.

Треды, с другой стороны, - это низкоуровневая концепция, предоставляемая операционной системой. Они имеют свой собственный стек вызовов и выделяют свои ресурсы, что делает их более тяжеловесными, чем горутины. В Go треды не являются частью стандартной библиотеки и должны быть реализованы вручную с помощью низкоуровневого пакета `sync/atomic`.

Горутины и треды отличаются в своей реализации и поведении. Горутины управляются гошным шедулером, который гарантирует, что не возникнет проблем с синхронизацией. Они могут быть созданы с помощью ключевого слова `go` и имеют динамически расширяемый стэк. Треды, с другой стороны, управляются ядром операционной системы и имеют свой собственный стек вызовов и ресурсы.

В целом, горутины - это легковесные и эффективные параллельные механизмы, уникальные для Go, которые могут быть созданы и управляемы с помощью стандартной библиотеки runtime.

## Defer (дефер)

`defer` в **Golang** - это ключевое слово, которое используется для отложенного выполнения функции или метода до тех пор, пока текущая функция не завершится. Когда встречается оператор `defer`, **Golang** добавляет вызов функции или метода в стек отложенных вызовов, а затем продолжает выполнение текущей функции.

`defer` может быть использовано для управления ресурсами, таких как файлы или сетевые соединения, чтобы гарантировать, что они будут закрыты независимо от того, как завершится функция. Он также может быть использован для обработки ошибок, когда функция должна быть завершена раньше времени.
## Panic (паника)

`panic` - это встроенная функция в Go, которая останавливает выполнение текущей горутины и вызывает функцию `defer` в обратном порядке. Она используется для обработки критических ошибок, которые не могут быть обработаны в нормальном потоке выполнения программы. `panic` может быть обработана с помощью функции `recover`, которая может быть вызвана в функции `defer` для перехвата паники и восстановления выполнения программы.

обработка паник осуществляется с помощью panic recover

С помощью panic("Ошибка парсинга") мы создаем панику

С помощью recover() мы обрабатываем ошибку
```Go
defer func() {
	panicValue := recover()
	fmt.Println(panicValue)
}
```

Если паника произошла, значение будет текст этой паники, если нет nil
## Chan, select (канал)

Каналы - это инструмент коммуникации который позволяет обмениваться данными между горутинами. Они обеспечивают безопасный и эффективный механизм взаимодействия между параллельно выполняемыми задачами.

Структура канала (это не всё... ТОЛЬКО ОСНОВНОЕ):
```Go
type chan struct {
	nx sync.mutex
	buffer []T
	readers []Goroutines
	writers []Goroutines
}
```

Буферизированные - это каналы, в которых есть буфер, и мы можем записывать в него данные, пока он не заполнится. Буферизированные каналы позволяют отправителю передавать данные, даже если получатель еще не готов к их приему.

Небуферизированные -  это каналы, которые не имеют буфера. Когда мы записываем данные в небуферизированный канал, мы блокируемся и ждем, пока кто-то прочтет эти данные. Если никто не прочтет, будет deadlock.

Пустые каналы - это каналы, которые не могут быть использованы для передачи данных. Мы не можем ни читать, ни записывать в пустые каналы.

Каналы создаются с помощью функции `make` и могут быть буферизированными или небуферизированными, в зависимости от указания емкости буфера при создании канала.

Кроме того, каналы могут быть закрыты с помощью функции `close`, что предотвращает дальнейшую передачу данных через канал.

В целом, каналы - это мощный инструмент для обеспечения безопасной и эффективной коммуникации между горутинами в Go.

Допустим что то пишем в канал, если буф будет возможность писать в этот канал пока буфер не забъётся, происходит зависание, там по моему какая то очередь формируется. Ну и пока мы не начнем вычитывать так и будем висеть, как только начнем, начнет его отпускать. Ну и та же самая история небуф, там также будет ждать и всё. 

Под капотом канала лежит мьютекс 

Если лочить два мьютекса можно напороться на deadlock, друг друга будут ждать.

У канала есть Len и Capasity

Создание канала:
- var nilChanel chan int // будет канал со значением NIL
	- Нельзя записать и прочитать данные, будет DEADLOCK
- unbufferedChanel := make(chan int) // небуферизированный
	- Обязательно должен быть и слушатель и читатель 1:1, иначе DEADLOCK
	- В закрытый канал нельзя записывать PANIC
- bufferedChanel := make(chan int, 2) // буферезированный

#select имеет 3 вида выполнения: блокирующая и неблокирующая опирации и дефолт. Select в первую очередь выполняет неблокирующие опирации, если их несколько, он выполнит рандомную. Ветка дефолт нужна, чтобы код не завис при попытке select выполнить блокирующую операцию. Для работы мы можем использовать механизм time.After(время), по истичению времени, select выполнит код который ждал окончания After. Graceful shutdown позволит програме не сразу остановится, а дать ей время на закрытие каналов и выполнение какого-нибудь кода.
## Context (контекст)

Контекст в Go - это тип, который хранит информацию о выполнении задачи, включая таймауты, сигналы отмены и другие значения, связанные с запросом. Он используется для управления выполнением задач и синхронизации между горутинами.

Контекст может быть создан с помощью функций `TODO`, `Background`, `WithValue`, `WithCancel`,`WithDeadline` и  `WithTimeout`. Каждый из этих типов контекста имеет свои особенности и используется в различных ситуациях.

- `TODO` - это контекст, который используется, когда не ясно, какой контекст использовать. Он не имеет таймаута и не может быть отменен.
- `Background` - это контекст, который не имеет таймаута и не может быть отменен. Он используется в основном функциях, инициализации и тестах.
- `WithValue` - это контекст, который хранит значения, связанные с запросом. Он используется для передачи данных между функциями.
- `WithCancel` - это контекст, который может быть отменен. Он используется для управления выполнением задач и синхронизации между горутинами.
- `WithDeadline` - это контекст, который имеет таймаут. Он используется для управления выполнением задач с ограничениями по времени.
- `WithTimeout` - это тип контекста, который создает контекст с таймаутом. Он используется для ограничения времени выполнения задачи. Если задача не будет выполнена в течение указанного времени, контекст будет отменен, и будет отправлен сигнал в канал `Done`.

Контекст может быть отменен с помощью функции `Cancel`, которая отправляет сигнал в канал `Done`. Это позволяет синхронизировать выполнение задач и остановить выполнение, если контекст был отменен.

В целом, контекст - это мощный инструмент в Go, который позволяет управлять выполнением задач и синхронизировать выполнение между горутинами.

1) context.Background()
	1) кладем данные которые нам понадобяться дальше, к примеру куки, данные клиента, т.д.
	2) Background создает наш корневой контекст
2) context.TODO()
	1) сообщать о завершении 
	2) TODO нужно юзать только в тестах, на этапах разработки, не совсем важный

методы:
- WithValue // добавляет значение ключ значение
- WithCancel // получаем функцию которая может отменить наш контекст
- With Deadline // завершение через время
- With timeout // чаще юзают 

Кроме этого можно в контексты накидывать свои какие то значения и там есть для этого интерфейс, методы у интерфейса, ну типо можно докинуть туда информацию авторизационную, токен какой нибудь пришел мы его распарсили и туда положили, роли там которые тоже в токене были распарсить положить.
## Atomic

Атомарность - операция которая выполняется целиком, без возможности прерывания Пакет позволяющий использовать атомарность в Го, что позволит ускорить код еще в сотни раз, по отношению с мьютексом. Его секрет, в том что он работает на уровне процессора, а минус, что он пропускает только одну операцию, пакет вызывается: “sync/atomic”, имеет данный синтаксис: atomic.AddТип(&переменная, наЧтоПоменять). Метод LoadТ() - позволяет атомарно получить значение. StoreT() позволяет атомарно положить значение в переменную. SwapT() наоборот, вытаскивает значение из переменной. 
## Дженерики 

После создания функции, в квадратных скобках мы можем создать обобщенный тип, который будет использовать в данной функциональной области: func [T float | int64](slace[ ]T) T { }. При этом использовать оба типа нельзя, мы можем использовать один из идущих на вход типов. В качестве типов данных идущих на вход можно использовать comparsble, то есть все типы данных кроме maph подобных и также структуру не имеющую внутри себя map и тд. Также для удобства использования дженериков были созданы специальные интерфейсы типа any - все типы данных, и тд. Если мы хотим расширить приминение обычных типов, мы можем реализовать это через интерфейсы и дженерики. И последняя классная функция это приближение типов, при использовании ~T, мы сможем использовать все типы основаные на T.

## Ошибки 

В Go ошибки обрабатываются с помощью возвращаемого значения типа `error` из функции. Если функция возвращает ошибку, то она может быть обработана с помощью условного оператора `if err != nil`.

Кроме того, в Go есть несколько способов создавать ошибки, таких как `errors.New` и `fmt.Errorf`, которые позволяют создавать ошибки с кастомизированными сообщениями.

Также, в Go есть сторонние пакеты, которые могут помочь в обработке ошибок, такие как `go.uber.org/zap` для логирования ошибок.

В целом, обработка ошибок в Go отличается от других языков, где ошибки обрабатываются с помощью исключений. В Go ошибки обрабатываются явно, с помощью возвращаемого значения типа `error` и условных операторов.
## ООП в Go

В Go нет классического ООП, но есть похожие возможности. Нет классов, объектов, исключений и шаблонов, но есть возможность описывать свои типы или структуры.
По сути структуры с методами служат тем же целям, что и классы в других языках.

Инкапсуляция в Go реализована на уровне пакетов. Названия начинающиеся со строчной буквы будут видны только внутри пакета, а с заглавной - доступно извне пакета.

Нет наследования, но есть структуры - типы данных, которые могут включать в себя другие типы, в том числе и такие же структуры. При встраивании реализация дочерних методов перезаписывает реализацию родительских.

Полиморфизм за счет структур и интерфейсов, а именно создания методов с одинаковым названием для разных структур.


__________________________________________________________
## Mutex


```Go
func writeWithMutex() {
	start := time.Now()
	var counter int
	var wg sync.WaitGroup
	var mu sync.Mutex

	wg.Add(1000)
	for i := 0; i < 1000; i++ {
		go func() {
			defer wg.Done()
			time.Sleep(time.Nanosecond)

			mu.Lock()
			counter++
			mu.Unlock()
		}()
	}
	wg.Wait()

	fmt.Println(counter)
	fmt.Println(time.Now().Sub(start).Second())
}
```

ПРИ ВЫПОЛНЕНИИ КРИТИЧНОГО УЧАСТКА КОДА, В НАШЕМ СЛУЧАЕ ЗАПИСИ COUNTER, НУЖНО ИСПОЛЬЗОВАТЬ БЛОКИРОВКУ ЧЕРЕЗ MUTEX, ЧТОБЫ ДАННЫЕ ЗАПИСЫВАЛА КАКАЯ ТО ОДНА ГОРУТИНА, А ПОТОМ НУЖНО РАЗБЛОКИРОВАТЬ.

У MUTEX ЕСТЬ МЕТОДЫ:
	С ПОМОЩЬЮ НИХ МОЖНО НАЛАДИТЬ ПОТОКОБЕЗОПАСНОСТЬ ГОРУТИН

m.Lock() - БЛОКИРОВКА ВСЕХ ГОРУТИН, КРОМЕ ОДНОЙ

m.Unlock() - РАЗБЛОКИРОВКА ВСЕХ ГОРУТИН
## RWmutex

В случае если мы хотим сделать блокировку на чтение, быстрее (примерно в 2 раза) будет работать RWMutex, у него есть следующие методы:

RLock() - блокирует горутины на чтение

RUnLock() - разблокирует горутины на чтение

Использование RWMutex может увеличить параллелизм в программе, так как позволяет много потоков читать данные без блокировки, в то время как обычный Mutex предотвращает любой доступ, кроме одного потока, во время записи или чтения.

## WaitGroup - инструмент синхронизации

```Go
func withWait() {
	var wg sync.WaitGroup

	//wg.Add(10) - одно и то же получится
	for i := 0; i < 10; i++ {
		wg.Add(1)

		go func() {
			// defer wg.Done()
			fmt.Println(i + 1)
			wg.Done()
		}(i)
	}

	wg.Wait()
	fmt.Println("Exit")
}
```


WaitGroup - это средство в Go для синхронизации горутин (goroutine). WaitGroup используется для дожидания завершения выполнения набора горутин перед продолжением работы основного потока.


wg.Add() - добавление задачи на ожидание
	ДОБАВЛЯТЬ ЗАДАЧУ НУЖНО ПЕРЕД ГОРУТИНОЙ, А НЕ ИЗНУТРИ

wg.Done() - говорим о том что мы выполнили эту задачу
	КАК ТОЛЬКО ВЫПОЛНИМ ОТЧИТЫВАЕМСЯ ЧТО ЗАВЕРШИЛИ

wg.Wait() - переходит из запущенного состояния в заблокированное, то есть она находится в состояние ожидания
	ДОЖИДАЕМСЯ ВЫПОЛНЕНИЯ ВСЕХ ЗАДАЧ

___________________________________________________
## Сборщик мусора

Гарбиш коллектор реализован с помощью алгоритма Mark and Sweep - трехцветный.

Как работает алгоритм:
- Данные в куче рассматриваются как граф связанных объектов
- Каждый объект может быть раскрашен белым серым или черным
- Изначально все белые
- После мы начинаем сканировать корневые объекты - помечаем серым
- Дальше выбираем серый объект из очереди и сканируем на наличие указателей помечаем черным
- Найденные объекты помечаются серым цветом, а исходный объект черным
- И повторяем это до тех пор, пока очередь серых объектов не станет пустой
- В итоге остаются только черные и белые объекты
- Белые объекты являются мусором, так как на них больше не ссылается ни одна переменная и их можно удалить

Приостановка программы сборщиком мусора может быть вызвана следующими причинами:

 Высокая нагрузка: Когда программа выделяет большое количество памяти за короткое время, сборщик мусора может приостановить программу для ее очистки.
 Большое количество объектов: Если в памяти находится очень много объектов, сборщику мусора может потребоваться больше времени для их обработки.
 Длительное выполнение цикла сборки мусора: Сборщик мусора может приостановить программу, если текущий цикл сборки мусора занимает слишком много времени.
 Некорректное использование памяти: Если программа неправильно выделяет или освобождает память, сборщик мусора может приостановить программу, чтобы попытаться исправить ситуацию.

Чтобы минимизировать остановки программы сборщиком мусора, следует:

 Оптимизировать выделение и освобождение памяти в программе.
 Использовать объекты с ограниченным сроком службы.
 Избегать создания большого количества кратковременных объектов.
 Настраивать параметры сборщика мусора для конкретного приложения.
# Пакеты 

## WaitGroup

sync.WaitGroup - Еще одну возможность по синхронизации горутин.Этот тип позволяет определить группу горутин, которые должны выполняться вместе как одна группа. И можно установить блокировку, которая приостановит выполнение функции, пока не завершит выполнение вся группа горутин.

Вначале определяем группу в виде переменной `wg sync.WaitGroup`. С помощью метода  *Add* определяем, что группа будет состоять из двух элементов

Чтобы сигнализировать, что элемент группы завершил свое выполнение, в горутине необходимо вызвать метод `Done()`

метод `Wait()`, который ожидает завершения всех горутин из группы wg

Await — это удобная функция, которую можно использовать вместо WaitGroup, предоставляемой этим пакетом. Await блокируется до тех пор, пока Waiter не вернется или не истечет указанное время ожидания. В случае превышения тайм-аута возвращается ошибка ErrTimeout, и внутренняя горутина может просочиться, если Waiter никогда не вернется.

AwaitWithError — это удобная функция, которую можно использовать вместо WaitGroup, предоставляемой этим пакетом. AwaitWithError блокируется до тех пор, пока WaitErrorer не вернется или не будет превышено указанное время ожидания. Любая ошибка от WaitErrorer будет возвращена, если ранее не было превышено время ожидания. В случае превышения тайм-аута возвращается ошибка ErrTimeout, и внутренняя горутина может просочиться, если WaitErrorer никогда не вернется.

WaitErrorer — это блокировка интерфейса при вызове Wait() и возврат любой ошибки, возникшей при вызове Wait(). errgroup.Group реализует этот интерфейс.

WaitGroup оборачивает sync.WaitGroup и добавляет метод WaitTimeout для прерывания ожидания длительных, заблокированных или протекших горутин, блокирующих Wait() из базовой группы WaitGroup. Вызывающий может использовать эту функцию для завершения программы за ограниченное время.

WaitTimeout блокируется до тех пор, пока счетчик WaitGroup не станет нулевым или пока не будет превышено время ожидания. Он порождает внутреннюю горутину. В случае превышения тайм-аута возвращается ошибка ErrTimeout, и внутренняя горутина может просочиться, если базовая группа WaitGroup никогда не вернется.

Waiter — это блокировка интерфейса в Wait(). sync.WaitGroup реализует этот интерфейс.

## fmt 

В **Go** **fmt** - это пакет, который предоставляет функциональность для форматирования и вывода данных в стандартный поток вывода (консоль) или в любой другой поток вывода.

Некоторые из наиболее распространенных функций пакета **fmt**:

1. `fmt.Print` - выводит значения переменных без форматирования и добавляет символ новой строки в конце.
2. `fmt.Println` - выводит значения переменных без форматирования, добавляет символ новой строки в конце и очищает буфер вывода.
3. `fmt.Printf` - выводит значения переменных с использованием форматирования строк, подобно функции **printf** в языке C.

В пакете **fmt** также есть возможность форматирования строк, что делает его полезным для создания строк с динамически подставляемыми значениями. Функции форматирования строк такие как `Sprintf`, `Fprintf` и `Printf` принимают строку формата и список аргументов, которые будут вставлены в форматируемую строку.

Кроме того, пакет **fmt** также поддерживает чтение данных из стандартного ввода с помощью функций `Scan`, `Scanf` и `Scanln`.

Append formats, используя форматы по умолчанию для своих операндов, добавляет результат к байтовому срезу и возвращает обновленный срез.

Appendf форматирует в соответствии со спецификатором формата, добавляет результат к байтовому срезу и возвращает обновленный срез.

Appendln форматирует, используя форматы по умолчанию для своих операндов, добавляет результат к байтовому срезу и возвращает обновленный срез. Между операндами всегда добавляются пробелы и добавляется новая строка.

Errorf форматирует в соответствии со спецификатором формата и возвращает строку как значение, соответствующее ошибке.

FormatString возвращает строку, представляющую полную директиву форматирования, полученную состоянием, за которой следует глагол-аргумент.Результат имеет ведущий знак процента, за которым следуют любые флаги, ширина и точность. Отсутствующие флаги, ширина и точность опускаются. Эта функция позволяет форматтеру восстановить исходную директиву, запускающую вызов Format.

Fprint форматирует, используя форматы по умолчанию для своих операндов, и записывает в w. Пробелы добавляются между операндами, если ни один из них не является строкой. Он возвращает количество записанных байтов и все обнаруженные ошибки записи.

Fprintf форматирует в соответствии со спецификатором формата и записывает в w. Он возвращает количество записанных байтов и все обнаруженные ошибки записи.

Fprintln форматирует, используя форматы по умолчанию для своих операндов, и записывает в w. Между операндами всегда добавляются пробелы и добавляется новая строка. Он возвращает количество записанных байтов и все обнаруженные ошибки записи.

Fscan сканирует текст, считанный из r, сохраняя последовательные значения, разделенные пробелами, в последовательные аргументы. Новые строки считаются пробелом. Он возвращает количество успешно отсканированных элементов. Если это число меньше количества аргументов, err сообщит, почему.

Fscanf сканирует текст, считанный из r, сохраняя последовательные значения, разделенные пробелами, в последовательные аргументы, как это определено форматом. Он возвращает количество успешно проанализированных элементов. Новые строки во входных данных должны соответствовать новым строкам в формате.

Fscanln похож на Fscan, но останавливает сканирование на новой строке, и после последнего элемента должна быть новая строка или EOF.

Printf форматирует в соответствии со спецификатором формата и записывает в стандартный вывод. Он возвращает количество записанных байтов и все обнаруженные ошибки записи.

Println форматирует свои операнды, используя форматы по умолчанию, и записывает в стандартный вывод. Между операндами всегда добавляются пробелы и добавляется новая строка. Он возвращает количество записанных байтов и все обнаруженные ошибки записи.

Scan сканирует текст, считанный со стандартного ввода, сохраняя последовательные значения, разделенные пробелами, в последовательные аргументы. Новые строки считаются пробелом. Он возвращает количество успешно отсканированных элементов. Если это число меньше количества аргументов, err сообщит, почему.

Scanf сканирует текст, считанный со стандартного ввода, сохраняя последовательные значения, разделенные пробелами, в последовательные аргументы, как это определено форматом. Он возвращает количество успешно отсканированных элементов. Если это число меньше количества аргументов, err сообщит, почему. Новые строки во входных данных должны соответствовать новым строкам в формате. Единственное исключение: глагол %c всегда сканирует следующую руну во входных данных, даже если это пробел (или табуляция и т. д.) или новая строка.

Scanln похож на Scan, но останавливает сканирование на новой строке, а после последнего элемента должна быть новая строка или EOF.

Sprint форматирует, используя форматы по умолчанию для своих операндов, и возвращает результирующую строку. Пробелы добавляются между операндами, если ни один из них не является строкой.

Sprintf форматирует в соответствии со спецификатором формата и возвращает результирующую строку.

Sprintln форматирует, используя форматы по умолчанию для своих операндов, и возвращает результирующую строку. Между операндами всегда добавляются пробелы и добавляется новая строка.

Sscan сканирует строку аргумента, сохраняя последовательные значения, разделенные пробелами, в последовательных аргументах. Новые строки считаются пробелом. Он возвращает количество успешно отсканированных элементов. Если это число меньше количества аргументов, err сообщит, почему.

Sscanf сканирует строку аргумента, сохраняя последовательные значения, разделенные пробелами, в последовательные аргументы в соответствии с форматом. Он возвращает количество успешно проанализированных элементов. Новые строки во входных данных должны соответствовать новым строкам в формате.

Sscanln аналогичен Sscan, но сканирование останавливается на новой строке, а после последнего элемента должна быть новая строка или EOF.

## gRPC

![[Pasted image 20240425191704.png]]

gRPC – это архитектура и система API с открытым исходным кодом, управляемая Cloud Native Computing Foundation. Она основана на модели удаленного вызова процедур (RPC). Хотя модель RPC обширна, gRPC обладает особой реализацией.
### **Что такое RPC?**

В RPC взаимодействие между клиентом и сервером происходит так, как если бы клиентский API-запрос был локальной операцией или запрос был внутренним кодом сервера.

В RPC клиент отправляет запрос процессу на сервере, который постоянно прослушивает удаленные вызовы. В запросе содержится вызываемая серверная функция и все передаваемые параметры. RPC API использует в качестве базового механизма обмена данными протокол типа HTTP, TCP или UDP.
### **Чем gRPC отличается от RPC?**

gRPC – это система, реализующая традиционный RPC с несколькими оптимизациями. Например, gRPC использует Protocol Buffers и HTTP 2 для передачи данных.

Она также абстрагирует механизм обмена данными от разработчика. Например, другая широко распространенная реализация RPC API, OpenAPI, требует от разработчиков сопоставления концепций RPC с протоколом HTTP. Но gRPC абстрагирует базовую HTTP-связь. Эти оптимизации делают gRPC быстрее, проще в реализации и удобнее для работы в Интернете по сравнению с другими реализациями RPC.
Другие ключевые отличия gRPC и REST

****Другие ключевые отличия gRPC и REST****

Помимо архитектурного стиля, gRPC и REST имеют и другие присущие отличия.

### **Взаимозависимость «клиент-сервер»**

REST имеет слабую взаимосвязь, то есть клиент и сервер не должны ничего знать о реализации друг друга. Такая взаимозависимость облегчает доработку API со временем, поскольку изменение определений сервера не обязательно требует изменения кода на стороне клиента.

gRPC имеет сильную взаимосвязь, то есть клиент и сервер должны иметь доступ к одному и тому же файлу PROTO. Любые обновления файла требуют обновлений как на стороне сервера, так и на стороне клиента.Помимо архитектурного стиля, gRPC и REST имеют и другие присущие отличия.
### **Взаимозависимость «клиент-сервер»**

REST имеет слабую взаимосвязь, то есть клиент и сервер не должны ничего знать о реализации друг друга. Такая взаимозависимость облегчает доработку API со временем, поскольку изменение определений сервера не обязательно требует изменения кода на стороне клиента.

gRPC имеет сильную взаимосвязь, то есть клиент и сервер должны иметь доступ к одному и тому же файлу PROTO. Любые обновления файла требуют обновлений как на стороне сервера, так и на стороне клиента.
## Time

Пакет времени предоставляет функциональные возможности для измерения и отображения времени.

Функция time.Now() возвращает текущее местное время.

Если вместо этого требуется создать объект времени для определенной даты, можно воспользоваться функцией time.Date().

Существуют две основные функции для добавления времени к существующему времени. Следует помнить, что эти функции работают и для вычитания времени, просто вы добавляете отрицательную длительность.  
time.Add()

Функция sub() получает разность между двумя временами. Следует помнить, что функция sub не вычитает длительность из времени. Для этого, как ни странно, необходимо использовать функцию add().

Сравните два времени, чтобы увидеть, какое из них идет после другого  
Есть две функции, которые должны удовлетворить большинство ваших потребностей в сравнении времени.  
time.After()
## Sync

Пакет Sync предоставляет базовые примитивы синхронизации, такие как блокировки взаимного исключения. За исключением типов Once и WaitGroup, большинство из них предназначены для использования библиотечными подпрограммами низкого уровня. Синхронизацию более высокого уровня лучше осуществлять через каналы и связь.

OnceFunc возвращает функцию, которая вызывает f только один раз. Возвращаемая функция может вызываться одновременно.

OnceValue возвращает функцию, которая вызывает f только один раз и возвращает значение, возвращаемое f. Возвращаемая функция может вызываться одновременно.

OnceValues ​​возвращает функцию, которая вызывает f только один раз и возвращает значения, возвращаемые f. Возвращаемая функция может вызываться одновременно.

Cond реализует условную переменную, точку встречи для горутин, ожидающих или объявляющих о наступлении события.
Каждый Cond имеет связанный с ним Locker L (часто *Mutex или *RWMutex), который необходимо удерживать при изменении условия и при вызове метода Wait.
Cond нельзя копировать после первого использования.

NewCond возвращает новый Cond с Locker l.

Broadcast пробуждает все горутины, ожидающие c.

Signa пробуждает одну горутину, ожидающую c, если таковая имеется.

Wait атомарно разблокирует cL и приостанавливает выполнение вызывающей горутины. После последующего возобновления выполнения Wait блокирует cL перед возвратом.

Locker представляет собой объект, который можно заблокировать и разблокировать.

Map is like a Go map[any]any но безопасна для одновременного использования несколькими горутинами без дополнительной блокировки или координации. Загрузка, сохранение и удаление выполняются за амортизированное постоянное время.

#Мьютекс — это блокировка взаимного исключения. Нулевое значение мьютекса — это разблокированный мьютекс.

Мьютекс нельзя копировать после первого использования.

В терминологии модели памяти Go n-й вызов Unlock «синхронизируется перед» m-м вызовом Lock для любого n < m. Успешный вызов TryLock эквивалентен вызову Lock. Неудачный вызов TryLock вообще не устанавливает никакого отношения «синхронизируется раньше».

Pull — это набор временных объектов, которые можно сохранять и извлекать по отдельности.

Любой элемент, хранящийся в Pull, может быть удален автоматически в любое время без уведомления. Если в этом случае пул содержит единственную ссылку, элемент может быть освобожден.

Пул безопасен для одновременного использования несколькими горутинами.

Цель Pull — кэшировать выделенные, но неиспользуемые элементы для последующего повторного использования, снижая нагрузку на сборщик мусора. То есть это позволяет легко создавать эффективные, потокобезопасные списки свободных файлов. Однако он подходит не для всех свободных списков.
## Kafka 

Kafka — это распределенная система, состоящая из **серверов** и **клиентов** , которые обмениваются данными через высокопроизводительный сервер. Kafka запускается как кластер из одного или нескольких серверов, которые могут охватывать несколько центров обработки данных или облачных регионов. Некоторые из этих серверов образуют уровень хранения, называемый брокерами. На других серверах используется [Kafka Connect](https://kafka.apache.org/documentation/#connect) для непрерывного импорта и экспорта данных в виде потоков событий для интеграции Kafka с существующими системами, такими как реляционные базы данных, а также с другими кластерами Kafka.

Главная задача брокера — обеспечение связи и обмена информацией между приложениями или отдельными модулями в режиме реального времени.

**Брокер** — система, преобразующая сообщение от источника данных (продюсера) в сообщение принимающей стороны (консьюмера). Брокер выступает проводником и состоит из серверов, объединенных в кластеры.

**Продюсер** — поставщик данных, который генерирует сообщения — например, служебные события, логи, метрики, события мониторинга.

**Консьюмер** — потребитель данных, который читает и использует события, пример — сервис сбора статистики.

ТОПИКИ - это стрим данных, по сути это получение каких то однотипных событий.
в топике есть очередь и туда складываются и вынимаются данные. FIFO

В ТОПИКЕ могут быть партиции, грубо говоря это создание дополнительных потоков.

Стоит распределять партиции по брокерам. (чтобы избежать highload на один брокер)
Где хранятся данные топика - в LOG файлах (есть папки под каждую партицию и в них есть лог файлы) 
Удаление TTL(time-to-live)

Брокер - отвечает за прием передачу и хранение сообщений. ZooKeeper - вспомогательный продукт отвечающий за хранение состояния кластера, конфигурации и методанные Record - сами данные. Состоит из полей: key - поле для распределений сообщений по кластеру, value - данные, timestamp - время сообщений, haders - пары ключ - значение 
Producer - информационная система которая отправляет данные в кафку. Имеет функцию отправки acks c тремя параметрами 0 - отправителя не интересует подтверждение доставки, сообщения могут потеряется. 1 - отправитель ожидает доставки сообщения. -1 отправитель ждет синхронизации между всеми сообщениями 
Topic - то куда попадают данные, отправляются обратно в порядке СТЕКА. Разделен на partition, которые разделены между брокерами. Иногда кафка может неправтильно распределить эти данные и Топик будет нагружен, решается ручным конфигурированием. Эти данные хранятся в 3х файлах: .log .index .timeindex, последние 2 файла появляются если .log перегружен, всё вместе это segment 
Consumer - тот кто получает данные. Читает сообщения только из лидера патриции, сообщения можно объединять в пачке для совместного чтения, в конце должен загомонить чтение(auto/ manual-ручное)

## Rabbit 

RabbitMQ — это широко используемый брокер сообщений с открытым исходным кодом, реализующий протокол AMQP. Он предоставляет надежный, высокопроизводительный и масштабируемый способ обмена сообщениями между приложениями, службами и микросервисами.

Основные особенности:

 Поддержка AMQP 0.9.1 и 1.0: Обеспечивает совместимость с широким спектром клиентов и библиотек.
 Гибкая маршрутизация: Позволяет пользователям настраивать сложные правила маршрутизации для направленных сообщений на основе определенных критериев.
 Надежная доставка: Гарантирует, что сообщения будут доставлены получателям в порядке, даже в случае сбоев или отказов.
 Масштабируемость и отказоустойчивость: Может быть развернут в кластерах для обеспечения высокого уровня доступности и поддержки растущей нагрузки.
 Поддержка плагинов: Разрешает расширение функциональности за счет установки дополнительных плагинов и сторонних разработок.

Преимущества использования RabbitMQ:

 Уменьшенная связанность: Отделяет производителей и потребителей сообщений, обеспечивая более слабую связанность и гибкость.
 Масштабируемость и производительность: Обрабатывает миллионы сообщений в секунду с низкой задержкой и минимальными накладными расходами.
 Надежная доставка: Гарантирует, что сообщения будут доставлены в порядке и своевременно, даже при сетевых сбоях.
 Расширяемость: Позволяет предприятиям использовать сторонние плагины и интеграции для удовлетворения конкретных потребностей.

Типы обмена данными:

RabbitMQ поддерживает различные типы обмена сообщениями:

 Fanout: Распространяет сообщения всем подписанным на него очередям.
 Direct: Маршрутизирует сообщения на основе ключей маршрутизации.
 Topic: Позволяет подписываться на определенные темы и получать сообщения с соответствующими ключами маршрутизации.
 Headers: Игнорирует ключ маршрутизации и маршрутизирует сообщения на основе пользовательских заголовков.

Реализация:

RabbitMQ может работать в различных операционных системах, включая Linux, Windows и macOS. Он поддерживает несколько языков программирования через клиентские библиотеки, такие как Python (pika), Java (Spring AMQP) и C# (rabbitmq-dotnet-client).

Использование:

RabbitMQ широко используется в различных отраслях, включая:

 Электронная коммерция
 Финансовые технологии
 Логистика и цепочка поставок
 Интернет вещей
 Игры и развлечения

Вывод:

RabbitMQ — это надежный, масштабируемый и высокопроизводительный брокер сообщений, который обеспечивает надежную и гибкую коммуникацию между приложениями и микросервисами. Его поддержка AMQP, различных типов обмена сообщениями и возможности расширения делают его ценным инструментом для создания надежных и масштабируемых систем обмена сообщениями.

![[Pasted image 20240416003411.png]]
![[Pasted image 20240416003429.png]]

![[Pasted image 20240416003527.png]]
## Отличия Rabbit от Kafka 

RabbitMQ и Apache Kafka - это две  ведущие платформы с открытым исходным кодом для потоковой передачи сообщений в реальном времени. Хотя обе платформы обеспечивают надежную и масштабируемую передачу сообщений, они различаются по архитектуре, особенностям и областям применения.

Архитектура:

 RabbitMQ: Брокер ориентированных на сообщения, следуя модели "точка-точка" или "публикация-подписка". Сообщения хранятся в очереди, и каждый подписчик получает собственный экземпляр сообщения.
 Kafka: Брокер распределенных журналов, следующий модели "публикация-подписка". Сообщения хранятся в разделах, и каждый подписчик может потреблять определенные разделы или все разделы.

Особенности:

 RabbitMQ:
     Зеркалирование очередей для обеспечения высокой доступности.
     Поддержка различных протоколов обмена сообщениями, таких как AMQP и MQTT.
     Встроенные плагины для дополнительной функциональности.
 Kafka:
     Комитирование по порядку для обеспечения строгой доставки сообщений.
     Поддержка распределенных кластеров для высокой масштабируемости.
     Встроенные возможности потоковой передачи в реальном времени, такие как Kafka Streams.

Области применения:

 RabbitMQ:
     Микросервисные архитектуры.
     Интеграция систем.
     Буферы обработки сообщений.
 Kafka:
     Потоковые обработки данных в реальном времени.
     Создание конвейеров данных.
     Управление событиями.

Сравнительная таблица:

| Характеристика | RabbitMQ | Kafka |
|---|---|---|
| Архитектура | Брокер ориентированных на сообщения | Брокер распределенных журналов |
| Модель обработки | Точка-точка или публикация-подписка | Публикация-подписка |
| Хранение сообщений | Очереди | Разделы |
| Доставка сообщений | По порядку | По порядку |
| Высокая доступность | Зеркалирование очередей | Распределенные кластеры |
| Поддержка протоколов | AMQP, MQTT | Только Kafka |
| Потоковая обработка данных | Ограниченная | Встроенная |
| Масштабируемость | Горизонтальное масштабирование | Горизонтальное и вертикальное масштабирование |

Вывод:

И RabbitMQ, и Kafka являются мощными платформами потоковой передачи сообщений. RabbitMQ лучше подходит для сценариев с низкой задержкой и высокой надежностью, а Kafka - для приложений с высокой пропускной способностью и потоковой обработкой данных в реальном времени. Выбор между ними зависит от конкретных требований приложения и ожидаемой нагрузки.

![[Pasted image 20240416003915.png]]

![[Pasted image 20240416004011.png]]

## OS 

Package os предоставляет независимый от платформы интерфейс для работы операционной системы.
## RunTime

Package runtime содержит операции, которые взаимодействуют с системой времени выполнения Go, например функции для управления горутинами. Он также включает низкоуровневую информацию о типах, используемую пакетом отражения

[net](https://pkg.go.dev/net) и [net/http]

GC запускает сборку мусора и блокирует вызывающую программу до завершения сборки мусора. Это также может заблокировать всю программу.

# Системный дизайн.

Системный дизайн - это процесс создания и оптимизации сложных систем, включающих в себя различные компоненты, такие как программное обеспечение, аппаратное обеспечение, сетевые инфраструктуры, данные и человеческие интеграции. Вот несколько ключевых тем, которые могут быть включены в собеседование по системному дизайну:

### 1. Проектирование масштабируемых систем:
   - Основные принципы масштабируемости систем, такие как горизонтальное и вертикальное масштабирование.
   - Выбор подходящих технологий и инструментов для обеспечения масштабируемости, управления нагрузкой и обеспечения высокой доступности.
   - Разработка архитектуры системы, учитывающей возможность масштабирования по мере роста бизнеса или увеличения нагрузки.

1. Горизонтальное и вертикальное масштабирование:
   - Вертикальное масштабирование подразумевает увеличение мощности отдельной машины (например, увеличение объема ОЗУ, процессорной мощности и т.д.).
   - Горизонтальное масштабирование предполагает добавление новых машин (или узлов) для распределения нагрузки.

2. Технические решения и инструменты:
   - Использование технологий и инструментов, которые позволяют обеспечить горизонтальное масштабирование, таких как контейнеры, оркестраторы, технологии распределенного хранилища данных и т.д.
   - Управление нагрузкой, балансировка нагрузки и отказоустойчивость для обеспечения непрерывной работы системы.

3. Принятие решений о масштабируемости:
   - Выбор подходящей стратегии масштабирования в зависимости от специфики системы и ее ожидаемых нагрузок.
   - Учет того, что изменения в архитектуре для обеспечения масштабируемости могут повлиять на другие аспекты системы, такие как безопасность, производительность и надежность.

4. Высокая доступность:
   - Обеспечение непрерывной работоспособности системы даже в случае отказа отдельных компонентов или узлов.
   - Резервирование ресурсов, использование репликации и распределение нагрузки для предотвращения единой точки отказа.
### 2. Архитектурные шаблоны:
   - Монолитная архитектура: Основные принципы и преимущества/недостатки этого подхода к разработке программных систем.
   - Микросервисная архитектура: Как разделять функциональность на микросервисы, принципы взаимодействия между ними и управление данными.
   - Серверless архитектура: Как проектировать и разрабатывать системы, основанные на серверless подходе, учитывая особенности выполнения функций, масштабируемость и надежность.

Эти шаблоны представляют собой основные структуры, которые помогают организовать компоненты системы и их взаимодействие. Вот более подробное описание ключевых архитектурных шаблонов:

1. Монолитная архитектура:
   - Монолитная архитектура представляет собой классический подход, при котором вся система развертывается как единое приложение.
   - Преимущества включают простоту развертывания и масштабирования на небольших масштабах.
   - Однако монолиты могут стать сложными и трудными в поддержке с увеличением размера и сложности проекта.

2. Микросервисная архитектура:
   - Микросервисы представляют собой подход, при котором система состоит из набора независимых служб, каждая из которых отвечает за конкретную функцию.
   - Преимущества включают легкость масштабирования, независимость развертывания и асинхронное развитие компонентов.
   - Однако управление микросервисной архитектурой требует хорошего понимания сетевой коммуникации и управления данными.

3. Серверless архитектура:
   - Серверless подход (или функциональное облако) предполагает написание кода как отдельных функций, которые запускаются по требованию.
   - Преимущества включают отсутствие необходимости управления инфраструктурой и оплаты только за фактическое использование ресурсов.
   - Однако серверless архитектура может иметь ограничения по времени выполнения операций и иные технические ограничения.
### 3. Базы данных и хранение данных:
   - Реляционные и нереляционные базы данных: Основные концепции, типы и сценарии использования.
   - Масштабируемость баз данных: Разделение данных, шардинг, репликация для обеспечения масштабируемости и высокой доступности.
   - Оптимизация запросов, индексирование и кэширование для обеспечения высокой производительности.
   - 
1. Реляционные и нереляционные базы данных:
   - Реляционные базы данных, такие как MySQL, PostgreSQL, MS SQL, используются для хранения табличных данных и обеспечивают структурированный подход к хранению информации.
   - Нереляционные базы данных, такие как MongoDB, Cassandra, используются для хранения неструктурированных данных, таких как JSON, и обеспечивают гибкий и масштабируемый подход.

2. Масштабируемость баз данных:
   - Разделение данных (шардинг), репликация и горизонтальное масштабирование для обеспечения эффективного использования ресурсов при росте данных и нагрузки.
   - Выбор подходящей технологии и стратегии масштабирования в зависимости от требований системы и ее данных.

3. Оптимизация запросов и индексирование:
   - Понимание методов оптимизации запросов, таких как реорганизация запросов, индексирование и кэширование, для обеспечения быстрого доступа к данным.
   - Создание эффективных схем баз данных и выбор оптимальных индексов для ускорения выполнения запросов.

4. Надежность и производительность:
   - Обеспечение надежности данных и защиты от потери данных с помощью резервирования, репликации и точек восстановления.
   - Оптимизация производительности баз данных с учетом объема данных, частоты запросов и типов выполняемых операций.

### 4. Производительность и масштабирование:
   - Архитектурные паттерны для обеспечения производительности и масштабируемости систем, такие как кэширование, асинхронная обработка, предварительная вычисления и т. д.
   - Планирование и прогнозирование нагрузки, мониторинг и оптимизация производительности системы.

Производительность системы определяет способность системы обрабатывать задачи и обеспечивать отзывчивость при работе с данными и запросами. Оптимизация производительности системы включает в себя улучшение скорости выполнения операций, уменьшение задержек и обеспечение эффективного использования ресурсов.

При проектировании систем с учетом масштабируемости и производительности важно учитывать следующие аспекты:

1. Архитектурные решения: Выбор подходящей архитектуры, которая позволяет горизонтальное масштабирование и распределенную обработку данных, такие как микросервисная архитектура или использование сообщений.

2. Оптимизация запросов: Эффективное проектирование баз данных, выбор подходящих индексов, использование кэширования данных и оптимизация SQL или NoSQL запросов.

3. Распределенная обработка: Использование техник распределенного вычисления и хранения данных, таких как шардинг, репликация и консистентность данных.

4. Мониторинг и оптимизация: Внедрение системы мониторинга, анализ производительности и оптимизация на основе полученных данных.
### 5. Безопасность систем:
   - Методы аутентификации и авторизации пользователей, учета угроз безопасности и защиты данных.
   - Шифрование данных в покое и в движении, обеспечение целостности данных и защита от уязвимостей.

1. Методы обеспечения безопасности: ознакомление с различными методами обеспечения безопасности, такими как использование сетевых брандмауэров, интеграция систем антивирусной защиты, внедрение процессов мониторинга безопасности и т.д.

2. Обнаружение и предотвращение угроз: знание методов обнаружения потенциальных угроз и предотвращения атак, включая системы обнаружения вторжений (IDS), системы защиты от распространения вредоносных программ (EDR) и другие.

3. Шифрование: понимание технологий шифрования данных в покое и в движении, включая использование SSL/TLS для шифрования сетевого трафика, а также практики шифрования хранения данных.

4. Аутентификация и авторизация пользователей: знание методов обеспечения подлинности пользователей при входе в систему, в том числе использование паролей, многофакторной аутентификации, биометрических данных и управления идентификацией.
### 6. Распределенные системы:
   - Принципы работы распределенных систем, консистентность данных, управление состоянием, обработка ошибок и восстановление после сбоев.
   - Взаимодействие между компонентами распределенной системы, методы гарантирования доставки сообщений, обеспечение согласованности данных.


1. Принципы работы распределенных систем: понимание концепций, лежащих в основе распределенных систем, таких как масштабируемость, отказоустойчивость, прозрачность и прочие.

2. Протоколы взаимодействия: ознакомление с различными протоколами коммуникации, используемыми для взаимодействия между компонентами распределенных систем, например, HTTP, REST, gRPC, MQTT и другими.

3. Согласованность данных: понимание проблем консистентности и согласованности данных в распределенных средах, а также методов и технологий для обеспечения целостности и согласованности данных в распределенных системах.

4. Модели распределенных вычислений: ознакомление с различными моделями распределенных вычислений, такими как клиент-серверная архитектура, микросервисы, а также технологии распределенных баз данных и обработки данных.

5. Технологии и платформы: ознакомление с современными технологиями и платформами, используемыми для создания распределенных систем, такими как контейнеризация (например, Docker, Kubernetes), облачные сервисы (Amazon Web Services, Microsoft Azure, Google Cloud Platform), а также распределенные базы данных (Cassandra, MongoDB, Redis).

6. Проблемы и вызовы: понимание проблем, с которыми сталкиваются разработчики распределенных систем, таких как обеспечение безопасности, мониторинга, отказоустойчивости, управления конфигурациями и масштабирования.

# Операционной системе и компьютерной архитектуре.

Операционные системы:
1. Основные функции операционной системы (управление ресурсами, управление процессами, файловая система и др.).
2. Типы операционных систем (однопользовательские, многопользовательские, однопрограммные, многозадачные и др.).
3. Процессы и потоки выполнения.
4. Управление памятью и виртуальная память.
5. Взаимодействие с устройствами ввода-вывода.
6. Методы синхронизации и взаимодействия между процессами.
7. Управление файловой системой.

Компьютерная архитектура:
1. Основные компоненты компьютерной системы (ЦП, ОЗУ, внешние устройства).
2. Принципы работы центрального процессора (ALU, регистры, устройство команд).
3. Типы и структуры памяти (кэш, RAM, ROM).
4. Ввод-вывод данных и управление устройствами.
5. Основные архитектурные концепции (понятие регистров, ассемблерного языка, машинного кода).
6. Виртуализация и понятие многопроцессорности.

Вот некоторые из основных команд консоли на Linux:
1. ls: Показывает список файлов и директорий в текущей директории.

2. cd: Переходит в указанную директорию. Например, cd /home/user перейдет в директорию пользователя "user".

3. pwd: Показывает полный путь текущей директории.

4. mkdir: Создает новую директорию. Например, mkdir new_directory создаст новую директорию с именем "newdirectory".

5. **touch**: Создает новый файл. Например, `touch newfile.txt создаст новый файл с именем "new_file.txt".

6. **rm**: Удаляет файл. Например, rm oldfile.txt` удалит файл с именем "oldfile.txt".

7. rmdir: Удаляет директорию. Например, rmdir old_directory удалит директорию с именем "olddirectory".

8. **cp**: Копирует файлы. Например, `cp file1.txt file2.txt` скопирует содержимое file1.txt в файл file2.txt.

9. **mv**: Перемещает или переименовывает файлы. Например, `mv file1.txt /newdirectory переместит file1.txt в директорию /new_directory.

10. **cat**: Выводит содержимое файла в консоль. Например, cat file.txt выведет содержимое файла file.txt.

11. **grep**: Позволяет искать текст в файлах. Например, grep "searchtext" file.txt` найдет строку с "searchtext" в файле file.txt.

12. chmod: Изменяет права доступа к файлам и директориям.

13. ps: Показывает информацию о запущенных процессах.

# Алгоритмы и патерны.

Алгоритмы представляют собой последовательность инструкций, направленных на решение определенной задачи или проблемы. Они являются основой для создания программ и определяют, какие шаги необходимо выполнить для достижения определенного результата. Алгоритмы могут быть использованы для сортировки данных, поиска определенного элемента, решения математических задач и многого другого.

Паттерны (шаблоны) проектирования — это способы построения программ, которые считаются хорошим тоном для разработчиков. Их еще называют шаблонами или образцами: чаще всего паттерн — это типовое решение для часто встречающейся задачи на построение (разбить структуру программы на формализованные классы и объекты.)

Важно понимать, как применять алгоритмы и паттерны в разработке программного обеспечения, чтобы создавать эффективные и структурированные приложения. Комбинирование подходов и выбор наиболее подходящих алгоритмов и паттернов для определенных задач помогает повысить качество программного продукта.

Сложность алгоритмов зависит от количества шагов алгоритма. К примеру константа имеет минимальное количество шагов, поэтому цикл с 10 и 1000 итераций будут на одной ступени сложности алгоритмов. Переменная с непостоянным значением используемая в цикле будет сильнее нагружать цикл. Две разных переменных будут нагружать цикл еще сильнее. Итерация - количество повторений одного и того-же действия
![[Pasted image 20240403140535.png]]

1. Константная сложность (O(1)): Алгоритм имеет постоянное время выполнения, что означает, что его производительность не зависит от количества входных данных.

2. Логарифмическая сложность (O(log n)): Время выполнения алгоритма возрастает логарифмически по отношению к размеру входных данных.

3. Линейная сложность (O(n)): Временная сложность алгоритма возрастает линейно по отношению к размеру входных данных.

4. Линейно-логарифмическая сложность (O(n log n)): Этот уровень сложности часто встречается в сортировочных алгоритмах, таких как быстрая сортировка и сортировка слиянием.

5. Квадратичная сложность (O(n^2)): Временная сложность алгоритма возрастает квадратично по отношению к размеру входных данных.

6. Экспоненциальная сложность (O(2^n) или O(n!)): Это самый медленный уровень сложности, где время выполнения алгоритма резко возрастает с увеличением размера входных данных.

# Тестирование

Unit testы Создаются в новом файле, который желательно называть именем тестируемого файла + _test, в нем мы создаем функцию с указателем на объект из пакета testing предназначенного для тестирования: func TestMax (t *testing.T){} Хорошая структура теста состоит из 3х этапов: Arrange(настройка тестовых данных), Act(Вызов тестируемого кода), Assert(проверка возвращаемых результатов).

**B2B** означает «business to business», то есть продажи «бизнеса для другого бизнеса».

TableDest - проходим по всем кейсам, проходим смотрим код.

Face  -  упрощённая реализация какого либо функционала 

Stub - упращенное решение (всегда отдает всегда готовый ответ(статична))

GoMock - (имитация реальной работы) нагенерить конкретным интерфейсам конкретные моки и дальше посмотреть значение, возвращаемое, поступаемое и смотреть что делает конкретный слой.

 -Unit tests – самые простые тесты, которые в большинстве своем не имеют каких-либо зависимостей. Тестирует отдельные куски кода.

-Integration tests – многоуровневое тестирование в котором уже есть некоторые зависимости или подключенные БДшки. Его сложнее написать, а также поддерживать, но при этом он может подсветить какой-то большой путь.

-E2E tests – самые дорогие тесты, их дорого писать и поддерживать, но иногда ими обкладывают критические участки функционала. (Сам еще не разу такие не писал)

# Протоколы 

OSI - 7ми уровневый процесс передачи данных: 
1. Физический уровень Передача электрических сигналов от источника к получателю, здесь мы оперируем кабелями, разъемами, кодированием единиц и нулей, короче уровнем проводов. К технологиям первого уровня относится интернет, блютус и тд. К сетевым устройствам относят концентраторы и репиторы, они просто передают пришедший сигнал.
2. Канальный уровень После получения сигнала с первого уровня происходит кодирование в биты, а именно первым делом исправляются ошибки передачи, отсюда берет свое начало понятие Mac-адрес и Frame - полезные данные с доп. информацией, в это время Mac-адрес служит для идентификации устройства и состоит из 48 символов. Здесь также есть свои устройства, коммутаторы и мосты, они служат для передачи Frame нужному адресату. Тут также есть стандарт интернет. 
3. Сетевой уровень Вводит термины IP и маршрутизация трафика - для того чтобы попасть на сайт, мы отправляем DNS запрос, получаем IP и подставляем его в пакет (схож с frame но хранит в себе не доп. информацию, а mac-адресы другого сетевого уровня). Инкапсуляция - процесс передачи информации с верхних на нижний уровень, если процесс происходит наоборот то это уже декапсуляция. На этом уровне с помощью протокола ICMP мы используем PING - помогает определить наличие проблем сети. Ну и наконец здесь появляется маршрутизатор который передает данные от источника к получатель только на уровне выше. 
4. Транспортный уровень Предназначен для надежной передачи данных по сети. Основу держат TCP (сообщения) и UDP (видео). Если точнее, то в случае когда трафик чувствителен к потерям, используется TCP, ведь он обеспечивает, чтобы информация дошла до получателя в целостности и сохранности , то есть при хотя бы одном измененном бите при пересылке, запрос уже будет не пропущен сервером. Если небольшие потери не страшны то используется UDP - он более оптимизирован и используется например для передачи видео на ютубе. На этом основные уровни заканчиваются, следующие три уровня больше относятся к разработчикам софта. 
5. Сеансовый уровень управляет соединением, и помогает им не разрываться во время различных процессов. Он также играет важную роль в звонках и устанавливает, каким кодеком, будет кодироваться сигнал, данный кодек после будет присутствовать у обоих пользователей. 
6. Уровень предстовления Происходит преобразование форматов сообщения, такое как кодирование или сжатие. Здесь при отправление jpeg или png картинки, она кодируется в единицы и нули, и благодаря этому уровню, раскодируется, обратно в картинку. 
7. Уровень Прикладной На этом уровне находятся службы которые помогают нам серфить интернет, например HTTPS, FTP и тд, уровень предназначен, для доступа приложений к различным службам по типу пересылке эл. сообщений, и запросам к базам данных.


# Разница между HTTP и HTTP2

HTTP и HTTP2 — это версии протокола передачи гипертекста (HTTP), используемого для передачи данных между веб-браузерами и веб-серверами.

Основные различия между HTTP и HTTP2:

1. Мультиплексирование:
 HTTP: Соединения между браузером и сервером однопоточные, что означает, что они могут обрабатывать только один запрос за раз.
 HTTP2: Поддерживает мультиплексирование, позволяя отправлять и получать несколько запросов и ответов по одному соединению одновременно.

2. Форматирование заголовка:
 HTTP: Заголовки запросов и ответов отправляются как текстовые строки.
 HTTP2: Заголовки сжимаются и передаются в двоичном формате HPACK, что значительно уменьшает их размер и повышает эффективность.

3. Приоритезация:
 HTTP: Все запросы обрабатываются с одинаковым приоритетом.
 HTTP2: Позволяет клиентам и серверам присваивать запросам приоритеты, что позволяет более важным запросам обслуживаться быстрее.

4. Потоковая передача:
 HTTP: Данные передаются в виде отдельных сообщений.
 HTTP2: Позволяет передавать данные в потоковом режиме, что упрощает передачу больших файлов и обновлений в реальном времени.

5. Сжатие HTTP:
 HTTP: Не имеет встроенного механизма сжатия.
 HTTP2: Встроенный механизм сжатия HPACK для уменьшения размера заголовков и улучшения производительности.

6. Уменьшение задержки:
 HTTP: Высокая задержка из-за заголовка TCP для каждого запроса.
 HTTP2: Снижает задержку за счет сжатия заголовков и использования одной очереди для всех запросов.

Сводная таблица:

| Характеристика | HTTP | HTTP2 |
|---|---|---|
| Мультиплексирование | Нет | Да |
| Форматирование заголовка | Текст | Двоичный (HPACK) |
| Приоритезация | Нет | Да |
| Потоковая передача | Нет | Да |
| Сжатие HTTP | Нет | HPACK |
| Задержка | Высокая | Низкая |

Преимущества HTTP2:

 Более быстрая и эффективная передача данных
 Уменьшение задержек
 Улучшенная масштабируемость
 Более надежная потоковая передача

В целом, HTTP2 является значительным улучшением по сравнению с HTTP, которое повышает скорость, эффективность и возможности современных веб-приложений.

# Разница HTTP и HTTPS

Клиент и сервер общаются по правилам, то есть по протоколам на последнем Прикладном уровне: HTTP (Hyper Text Transfer Protocol) — протокол передачи гипертекста HTTPS (Hyper Text Transfer Protocol Secure) — защищенный протокол передачи гипертекста

# Транзакции и уровни изоляции 

Транзакция — это набор операций по работе с базой данных (БД), объединенных в одну атомарную пачку.

В Golang, транзакции обычно используются при работе с базами данных, чтобы обеспечить атомарность операций. Транзакции позволяют выполнить несколько операций как один целостный блок, либо откатить все операции в случае ошибки в процессе выполнения.

Уровни изоляции определяют степень изоляции данных между различными транзакциями. В Golang поддерживаются следующие уровни изоляции:

1. Read Uncommitted: Позволяет транзакциям видеть результаты операций других транзакций до их фиксации. Этот уровень изоляции предоставляет самую низкую степень защиты от конфликтов данных.

2. Read Committed: Позволяет транзакциям видеть только фиксированные результаты операций других транзакций. Этот уровень изоляции обеспечивает более высокую степень защиты от конфликтов данных.

3. Repeatable Read: Гарантирует, что одна и та же выборка данных будет возвращать те же результаты в рамках одной транзакции. Этот уровень изоляции обеспечивает более высокую степень непрерывности данных.

4. Serializable: Самый высокий уровень изоляции, который гарантирует, что результаты операций других транзакций не повлияют на текущую транзакцию и наоборот. Этот уровень изоляции обеспечивает полную защиту от конфликтов данных, но при этом может привести к замедлению работы приложения из-за блокировок.

Каждый уровень изоляции имеет свои преимущества и недостатки, и выбор оптимального уровня зависит от конкретных требований вашего приложения. При работе с базами данных в Golang, уровни изоляции обычно устанавливаются с помощью драйверов баз данных или ORM библиотек.

# Индексы 

В Golang индексы используются для ускорения доступа к элементам коллекций данных, таких как массивы, слайсы и карты (мапы). Индекс представляет собой целочисленное значение, которое используется для обращения к конкретному элементу в коллекции.

Составные индексы в Golang используются, когда нужно обращаться к элементам, используя комбинацию нескольких значений в качестве индекса. Например, в многомерных массивах или слайсах, где каждый элемент может быть доступен по набору индексов.

Составные индексы удобны для работы с многомерными структурами данных, где необходимо обращаться к элементам с использованием нескольких индексов.
# CI/CD (непрерывная интеграция/непрерывное развертывание)
![[Pasted image 20240415143809.png]]

# PostgresSQL

Что такое PostgreSQL?

PostgreSQL — это система управления реляционными базами данных с открытым исходным кодом (СУБД). Она известна своими расширенными возможностями, надежностью и масштабируемостью.

Индексы

Индексы — это структуры данных, которые помогают ускорить поиск данных в таблицах. В PostgreSQL существует несколько типов индексов:

 B-Tree индексы: Обычные индексы, используемые для поиска одного столбца или нескольких столбцов в порядке сортировки.
 Красно-белое дерево (Red-Black tree) в PostgreSQL — это сбалансированное двоичное дерево поиска, которое используется для хранения данных по B-tree индексам.

Красно-белые деревья обладают следующими свойствами:

* **Все пути от корня до листьев имеют одинаковую длину.** Это обеспечивает быстрый поиск и вставку элементов с логарифмической сложностью.
* **Каждому узлу соответствует цвет (красный или черный).** Цвета узлов используются для поддержания баланса дерева.
* **Корень всегда черный.**
* **У любого красного узла оба дочерних узла являются черными.**
* **Черный путь от любого узла до любого из его потомков содержит одинаковое количество черных узлов.**

По сравнению с B-деревьями, красно-белые деревья обеспечивают более быстрый поиск и вставку за счет более строгой балансировки. Однако они потребляют больше памяти из-за необходимости хранения дополнительного поля цвета для каждого узла.

Hash индексы: Быстрые индексы, предназначенные для поиска по одному столбцу, содержащему уникальные значения.
 Индексы GIN: Индексы, предназначенные для поиска по нечетко сопоставленным или составным данным.
 Индексы SP-GIST: Пространственные индексы, используемые для поиска данных по их географическому расположению.
 Индексы BRIN: Сжатые индексы, используемые для ускорения сканирования больших таблиц.

Создание индекса:

```sql
CREATE INDEX [имя_индекса] ON [имя_таблицы] ([столбцы]);
```

Анализ запросов

Понимание того, как PostgreSQL выполняет запросы, имеет решающее значение для оптимизации производительности. Есть несколько способов проанализировать запрос:

 EXPLAIN: Показывает план выполнения запроса, включая используемые индексы и операции.
 EXPLAIN ANALYZE: Выполняет запрос и предоставляет дополнительную информацию, такую как количество обработанных строк и затраченное время.
 EXPLAIN BUFFERS: Показывает информацию об использовании буферов во время выполнения запроса.

Примеры анализа:

EXPLAIN SELECT * FROM users WHERE name = 'John';
EXPLAIN ANALYZE SELECT * FROM products WHERE price > 100;
EXPLAIN BUFFERS SELECT * FROM orders WHERE date BETWEEN '2023-01-01' AND '2023-12-31';

Методы индексов

В PostgreSQL существуют следующие типы индексов:

1. **B-дерево (B-tree)**: Это наиболее распространенный тип индекса, который эффективен в большинстве случаев. Он может работать с операторами равенства и диапазонов, а также с отсортированными данными.
2. **Хеш (Hash)**: Используется для запросов с оператором равенства. Он эффективен для точечных запросов, но может быть медленнее B-дерева при запросах по диапазону.
3. **GiST (Generalized Search Tree)**: Это инфраструктура, позволяющая реализовать различные стратегии индексирования. Она может быть использована для различных типов данных и операторов.
4. **SP-GiST (Space-Partitioned Generalized Search Tree)**: Это разновидность GiST, которая используется для индексирования данных с пространственными свойствами.
5. **GIN (Generalized Inverted Index)**: Используется для индексирования массивов и текстовых данных. Он может работать с операторами, такими как `<@`, `@>`, `=`, `&&`.
6. **BRIN (Block Range Index)**: Используется для индексирования больших объемов данных, когда создание полноценного индекса может быть ресурсоемким.
7. **RUM (Reverse Unified Matrix)**: Это тип индекса, который используется для индексирования данных с обратными ссылками.

Каждый тип индекса имеет свои особенности и используется для различных задач и типов запросов.

Агрегатные функции

Агрегатные функции в SQL выполняют вычисление над набором значений и возвращают одиночное значение. Они могут быть использованы для различных задач, таких как вычисление суммы, среднего, минимального и максимального значения, а также для подсчета количества строк. Некоторые из наиболее распространенных агрегатных функций включают:

1. **SUM**: Возвращает сумму значений в столбце.
2. **AVG**: Возвращает среднее значение в столбце.
3. **COUNT**: Возвращает количество строк в запросе.
4. **MIN**: Возвращает минимальное значение в столбце.
5. **MAX**: Возвращает максимальное значение в столбце.


# Оптимизация структур Go

Оптимизация структур Go имеет решающее значение для повышения производительности и эффективности приложения. Вот несколько рекомендаций:

Использование правильных типов данных:
 Используйте целочисленные типы (int, uint) вместо float64 для хранения целых чисел для экономии памяти.
 Выбирайте соответствующие размеры типов данных (например, int8 вместо int64 для небольших целочисленных значений).

Минимизация размера структуры:
 Избегайте вложенных структур и вместо этого используйте указатели или композицию.
 Располагайте поля с фиксированным размером (например, int) в начале структуры для улучшения выравнивания памяти.

Выравнивание границ памяти:
 Используйте теги для выравнивания структуры по границе памяти (например, 64-битной границе) для повышения эффективности кэширования ЦП.

Минимизация количества выделений памяти:
 По возможности используйте пулы объектов для повторного использования выделенной памяти.
 Избегайте создания и удаления структур во время выполнения, так как это может привести к фрагментации памяти.

Использование интерфейсов и композиции:
 Интерфейсы позволяют определять общие контракты между типами, позволяя использовать полиморфизм и избегать дублирования кода.
 Композиция позволяет создавать новые типы путем объединения существующих, что может улучшить гибкость и уменьшить размер кода.

Использование структур перечислений:
 Структуры перечислений позволяют создавать наборы именованных значений. Они более эффективны, чем строки, для представления предопределенных вариантов.

Примеры оптимизированных структур:

// Оптимизированная структура для хранения данных о пользователе
type User struct {
    ID       int64  // Целочисленный идентификатор
    Name     string // Имя пользователя
    Email    string // Электронная почта пользователя
}

// Оптимизированная структура для хранения данных о продукте
type Product struct {
    ID          int64   // Целочисленный идентификатор
    Name        string  // Название продукта
    Description string  // Описание продукта
    Price       float64 // Цена продукта
}


Помимо этих рекомендаций, используйте профилирование и другие инструменты для измерения производительности и выявления областей для улучшения. Регулярно проводите аудит и оптимизируйте структуры, чтобы поддерживать производительность приложения.

# ClickHouse

![[Pasted image 20240416010632.png]]
![[Pasted image 20240416010720.png]]
![[Pasted image 20240416010752.png]]
![[Pasted image 20240416010824.png]]
![[Pasted image 20240416010924.png]]
![[Pasted image 20240416010957.png]]


# TCP/IP

![[Pasted image 20240416011217.png]]
![[Pasted image 20240416011634.png]]
![[Pasted image 20240416011928.png]]


# Kubernetes (K8s)

![[Pasted image 20240416012146.png]]
![[Pasted image 20240416012819.png]]
![[Pasted image 20240416012844.png]]
![[Pasted image 20240416013020.png]]
![[Pasted image 20240416013037.png]]


# Docker 

![[Pasted image 20240416013142.png]]
![[Pasted image 20240416013304.png]]
![[Pasted image 20240416013330.png]]




# Middleware 

![[Pasted image 20240416013533.png]]
![[Pasted image 20240416013607.png]]


# OpenSearch

OpenSearch — это открытый стандарт поиска, основанный на спецификации Elasticsearch. Он обеспечивает единый интерфейс для поиска, сбора и хранения данных из разных источников.

Основные возможности OpenSearch:

 Полнотекстовый поиск: Позволяет выполнять поиск и извлекать релевантные данные из больших объемов неструктурированного текста.
 Агрегация данных: Предоставляет функции агрегации для группировки и обработки больших объемов данных, позволяя выявлять тенденции, шаблоны и статистику.
 Управление индексами: Позволяет создавать, управлять и настраивать индексы для оптимизации производительности поиска и релевантности.
 Поддерживает различные источники данных: Может подключаться к различным источникам данных, таким как базы данных SQL, системы NoSQL, веб-сайты, облачные хранилища и потоковые платформы.
 Масштабируемость и отказоустойчивость: Обеспечивает горизонтальное масштабирование и высокую доступность для обработки больших объемов данных и устойчивости к сбоям.

Преимущества OpenSearch:

 Открытый исходный код: Доступен под лицензией Apache 2.0, что позволяет пользователям настраивать и расширять его согласно своим потребностям.
 Высокопроизводительный: Использует распределенную архитектуру и оптимизирован для быстрой и эффективной обработки запросов поиска.
 Гибкий: Поддерживает различные источники данных, типы запросов и конфигурации для удовлетворения различных вариантов использования.
 Интегрируемый: Может быть интегрирован с другими инструментами и приложениями для создания комплексных решений для обработки данных.
 Совместимость: Совместим со спецификацией Elasticsearch, что позволяет легко мигрировать существующие приложения и использовать существующую документацию и инструменты.

Применение OpenSearch:

OpenSearch используется в широком спектре приложений, включая:

 Поиск в электронной коммерции
 Поиск предприятий
 Анализ журналов
 Мониторинг в реальном времени
 Анализ социальных сетей
 Разработка приложений

# Grafana

**Grafana** — это платформа с открытым исходным кодом для создания информативных и интерактивных дашбордов, которые визуализируют данные метрик и журналов.

**Основные возможности Grafana:**

* **Создание дашбордов:** Позволяет создавать настраиваемые дашборды с различными типами панелей, отображающих метрики, графики, таблицы и тексты.
* **Поддерживает различные источники данных:** Может подключаться к широкому спектру источников данных, таких как базы данных Prometheus, InfluxDB, Graphite, Elasticsearch и базы данных SQL.
* **Визуализации данных:** Предоставляет широкий спектр визуализаций данных, включая линейные графики, столбчатые диаграммы, карты и круговые диаграммы.
* **Агрегация и преобразование данных:** Позволяет агрегировать и преобразовывать данные с помощью функций, алиасов и подзапросов.
* **Оповещения и уведомления:** Может создавать оповещения и уведомления на основе определенных пороговых значений или условий.
* **Совместная работа и обмен:** Позволяет пользователям делиться и совместно работать над дашбордами, а также управлять правами доступа.

**Преимущества Grafana:**

* **Открытый исходный код:** Доступен под лицензией GPLv3, что позволяет пользователям настраивать его и расширять согласно своим потребностям.
* **Мощные возможности визуализации:** Предоставляет широкий спектр опций визуализации для эффективного отображения данных.
* **Интегрируемый:** Может быть интегрирован с другими инструментами и приложениями для создания комплексных решений для мониторинга.
* **Гибкий:** Поддерживает различные источники данных и настраиваемые параметры дашборда для удовлетворения различных вариантов использования.
* **Сообщество и поддержка:** Имеет большое и активное сообщество, которое предоставляет поддержку и ресурсы.

**Применение Grafana:**

Grafana используется в широком спектре приложений, включая:

* Мониторинг инфраструктуры
* Анализ производительности приложений
* Отслеживание бизнеса и метрик
* Мониторинг безопасности
* Управление журналами
* Анализ DevOps

# Sentry

Sentry — это платформа для мониторинга ошибок и производительности в реальном времени, которая помогает командам разработчиков выявлять, диагностировать и устранять проблемы в своих приложениях.

Основные возможности Sentry:

 Отслеживание ошибок: Автоматически отслеживает исключения и ошибки в приложениях и предоставляет подробную информацию об их стеке вызовов, переменных среды и других метаданных.
 Мониторинг производительности: Отслеживает и отображает метрики производительности, такие как время загрузки страниц, задержки сервера и использование памяти.
 Картирование стека вызовов: Визуализирует стек вызовов для каждой ошибки, помогая разработчикам быстро понять, где и почему произошел сбой.
 Агрегация и группировка: Агрегирует и группирует ошибки по типу, проекту, версии приложения и другим критериям для выявления закономерностей и тенденций.
 Оповещения и уведомления: Создает оповещения и отправляет уведомления по электронной почте, SMS или в инструменты чата на основе настраиваемых условий.
 Интеграции: Интегрируется с различными системами управления версиями, инструментами DevOps и системами чата для автоматизации рабочих процессов и совместной работы.

Преимущества Sentry:

 Проактивное обнаружение ошибок: Обнаруживает ошибки в реальном времени, даже если они не приводят к сбоям, помогая предотвращать прерывания обслуживания и снижать влияние ошибок.
 Подробная диагностика: Предоставляет подробные данные об ошибках, включая стеки вызовов, переменные окружения и метаданные журнала, упрощая диагностику.
 Улучшение производительности: Отслеживает показатели производительности и предоставляет рекомендации по оптимизации, помогая командам разработчиков создавать более быстрые и отзывчивые приложения.
 Сокращение времени на устранение неполадок: Сокращает время, необходимое для выявления, диагностики и устранения ошибок, повышая производительность разработчиков и сокращая прерывания обслуживания.
 Совместная работа и обмен: Позволяет командам разработчиков совместно работать над устранением ошибок, оставлять комментарии и делиться информацией.

Применение Sentry:

Sentry используется в широком спектре приложений, включая:

 Разработка веб-приложений
 Разработка мобильных приложений
 Разработка игр
 Микросервисная архитектура
 DevOps и автоматизация тестирования


# GitHub

## **Рабочий процесс**

git add: добавление файлов в индекс
git status: проверка статуса репозитория
git commit (-m): добавление файлов в репозиторий
git log: просмотр журнала коммитов
git show: просмотр коммита
git diff: просмотр изменений до коммита
git difftool: запуск внешнего инструмента сравнения 
git restore (--staged): отмена изменений
git rm (--cached): удаление файлов из индекса
git reset: откат коммита
## **Ветвление**

git branch <branch_name>: создание новой ветки
git branch: просмотр веток
git checkout: переключение между ветками
git merge: слияние репозиториев
git branch -d <branch_name>: удаление ветки
## **Удалённый репозиторий**

vgit remote add origin url: привязка локального и удалённого репозитория
git remote: просмотр удалённых репозиториев
git remote — v: просмотр удалённых URL-адресов
git push: отправка изменений в удалённый репозиторий
git pull: получение изменений из удалённого репозитория